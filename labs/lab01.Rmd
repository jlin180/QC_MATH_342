---
title: "Lab 1"
author: "Jia Yu Lin"
output: pdf_document
date: "11:59PM February 18, 2021"
---
  
  You should have RStudio installed to edit this file. You will write code in places marked "TO-DO" to complete the problems. Some of this will be a pure programming assignment. The tools for the solutions to these problems can be found in the class practice lectures. I want you to use the methods I taught you, not for you to google and come up with whatever works. You won't learn that way.

To "hand in" the homework, you should compile or publish this file into a PDF that includes output of your code. Once it's done, push by the deadline to your repository in a directory called "labs".

* Print out the numerical constant pi with ten digits after the decimal point using the internal constant `pi`.

```{r}
#TO-DO
options(digits=11)
x <- pi
x
```

* Sum up the first 103 terms of the series 1 + 1/2 + 1/4 + 1/8 + ...

```{r}
#TO-DO
sum(1/(2^(0:102)))
```

* Find the product of the first 37 terms in the sequence 1/3, 1/6, 1/9  ...

```{r}
#TO-DO
prod(1/(3*(1:37)))
prod(1/(seq(from =3, by =3,length.out = 37)))
```


* Find the product of the first 387 terms of `1 * 1/2 * 1/4 * 1/8 *` ...

```{r}
#TO-DO
prod(1/(2^(0:386)))
prod(1/(seq(from = 2, by=2, length.out = 387)))
#numeric underflow
```

Is this answer *exactly* correct? 
  
  #TO-DO
  The answer is not exactly correct because we experience numerical underflow.(If it goes under a certain amount, then it is treated as if it is 0 when it really is not).
  
  * Figure out a means to express the answer more exactly. Not compute exactly, but express more exactly.

```{r}
#TO-DO
sum(log(1/(2^(0:386))))
-log(2)*sum((0:386))
```

* Create the sequence `x = [Inf, 20, 18, ..., -20]`.

```{r}
#TO-DO
x <- c(Inf, seq(from = 20, to=-20, by=-2))
x
```

Create the sequence `x = [log_3(Inf), log_3(100), log_3(98), ... log_3(-20)]`.

```{r}
#TO-DO
x <- c(Inf,seq(from = 100, to =- 20, by=-2))
x <- log(x, base=3)
x
```

Comment on the appropriateness of the non-numeric values.

#TO-DO
log(Inf) = Inf because log of infinity comes out as infinity
log(0) = -Inf because log of 0 diverges so it becomes -Inf
log(negative numbers) = NaN because log of anyn negative numbers is undefined


* Create a vector of booleans where the entry is true if `x[i]` is positive and finite.

```{r}
#TO-DO
y = !is.nan(x) & is.finite(x) & x>0
y
```

* Locate the indices of the non-real numbers in this vector. Hint: use the `which` function. Don't hesitate to use the documentation via `?which`.

```{r}
#TO-DO
which(y == FALSE)
```

* Locate the indices of the infinite quantities in this vector. 

```{r}
#TO-DO
which(is.infinite(x) == TRUE)
```

* Locate the indices of the min and max in this vector. Hint: use the `which.min` and `which.max` functions.

```{r}
#TO-DO
which.max(x)
which.min(x)
```

* Count the number of unique values in `x`.

```{r}
#TO-DO
length(unique(x))
```

* Cast `x` to a factor. Do the number of levels make sense?

```{r}
#TO-DO
as.factor(x)
#there are 53 unique values so there are 53 unique nominal categories
```

* Cast `x` to integers. What do we learn about R's infinity representation in the integer data type?
  
```{r}
#TO-DO
as.integer(x)
#infinities get converted to NA because there is no Inf or NaN as an integer
```

* Use `x` to create a new vector `y` containing only the real numbers in x.

```{r}
#TO-DO
y= x[(!is.nan(x) & is.finite(x) & x>0)]
#this works because the inside of the square brackets returns true and false. It subsets the vector.
y

```

* Use the left rectangle method to numerically integrate x^2 from 0 to 1 with rectangle width size 1e-6.

```{r}
#TO-DO
sum((seq(from = 0, to = (1 - 1e-6), by= 1e-6)^2) * 1e-6)
#to make it more efficient so that the computer does the multiplications only once.
sum((seq(from = 0, to = (1 - 1e-6), by= 1e-6)^2))* 1e-6
```


* Calculate the average of 100 realizations of standard Bernoullis in one line using the `sample` function.

```{r}
#TO-DO

mean(sample(c(0,1), size=100, replace=TRUE))
```


* Calculate the average of 500 realizations of Bernoullis with p = 0.9 in one line using the `sample` and `mean` functions.

```{r}
#TO-DO
mean(sample(c(0,1), size=500, replace=TRUE, p = c(0.9,0.1)))
```


* Calculate the average of 1000 realizations of Bernoullis with p = 0.9 in one line using `rbinom`.

```{r}
#TO-DO
mean(rbinom(n= 1000, size=1, prob=0.9))
```

* In class we considered a variable `x_3` which measured "criminality". We imagined L = 4 levels "none", "infraction", "misdimeanor" and "felony". Create a variable `x_3` here with 100 random elements (equally probable). Create it as a nominal (i.e. unordered) factor.

```{r}
#TO-DO
x_3 = as.factor(sample(c("none", "infraction", "misdimeanor", "felony"), size=100, replace=TRUE))
x_3
```

* Use `x_3` to create `x_3_bin`, a binary feature where 0 is no crime and 1 is any crime.

```{r}
#TO-DO
x_3_bin = as.numeric(x_3 != "none")
x_3_bin
```

* Use `x_3` to create `x_3_ord`, an ordered factor variable. Ensure the proper ordinal ordering.

```{r}
#TO-DO
x_3_ord = factor(x_3, levels = c("none", "infraction", "misdimeanor", "felony"), ordered = TRUE)
x_3_ord

#can also use order instead of factor
```

* Convert this variable into three binary variables without any information loss and put them into a data matrix.

```{r}
#TO-DO
X = matrix( NA,nrow= 100, ncol = 3)
colnames(X) = c("infraction", "misdimeanor", "felony")
X[, "infraction"] = as.numeric(x_3_ord == "infraction")
X[, "misdimeanor"] = as.numeric(x_3_ord == "misdimeanor")
X[, "felony"] = as.numeric(x_3_ord == "felony")
X

```

* What should the sum of each row be (in English)? 
  
  #TO-DO
  The sum of each row represents if a person has committed a crime or not because it can only be 1 or 0.
  
  Verify that. 


```{r}
#TO-DO
as.matrix(rowSums(X), nrow = 100)
```

* How should the column sum look (in English)? 
  
  #TO-DO
  The sum of each column represents the number of people who committed that level of crime.
  
  Verify that.

```{r}
#TO-DO
colSums(X)

```

* Generate a matrix with 100 rows where the first column is realization from a normal with mean 17 and variance 38, the second column is uniform between -10 and 10, the third column is poisson with mean 6, the fourth column in exponential with lambda of 9, the fifth column is binomial with n = 20 and p = 0.12 and the sixth column is a binary variable with exactly 24% 1's dispersed randomly. Name the rows the entries of the `fake_first_names` vector.

```{r}
fake_first_names = c(
  "Sophia", "Emma", "Olivia", "Ava", "Mia", "Isabella", "Riley", 
  "Aria", "Zoe", "Charlotte", "Lily", "Layla", "Amelia", "Emily", 
  "Madelyn", "Aubrey", "Adalyn", "Madison", "Chloe", "Harper", 
  "Abigail", "Aaliyah", "Avery", "Evelyn", "Kaylee", "Ella", "Ellie", 
  "Scarlett", "Arianna", "Hailey", "Nora", "Addison", "Brooklyn", 
  "Hannah", "Mila", "Leah", "Elizabeth", "Sarah", "Eliana", "Mackenzie", 
  "Peyton", "Maria", "Grace", "Adeline", "Elena", "Anna", "Victoria", 
  "Camilla", "Lillian", "Natalie", "Jackson", "Aiden", "Lucas", 
  "Liam", "Noah", "Ethan", "Mason", "Caden", "Oliver", "Elijah", 
  "Grayson", "Jacob", "Michael", "Benjamin", "Carter", "James", 
  "Jayden", "Logan", "Alexander", "Caleb", "Ryan", "Luke", "Daniel", 
  "Jack", "William", "Owen", "Gabriel", "Matthew", "Connor", "Jayce", 
  "Isaac", "Sebastian", "Henry", "Muhammad", "Cameron", "Wyatt", 
  "Dylan", "Nathan", "Nicholas", "Julian", "Eli", "Levi", "Isaiah", 
  "Landon", "David", "Christian", "Andrew", "Brayden", "John", 
  "Lincoln"
)
#TO-DO
B = matrix(NA, nrow = 100, ncol = 6)
B[,1] = rnorm(n = 100, mean = 17, sd = sqrt(38))
B[,2] = runif(n = 100, min = -10, max = 10)
B[,3] = rpois(n = 100, lambda = 6)
B[,4] = rexp(n = 100, rate = 9)
B[,5] = rbinom(n = 20,size = 100,prob = 0.12)
B[,6] = rbinom(n = 100,size = 1, prob = 0.24)
rownames(B) = fake_first_names
B
```

* Create a data frame of the same data as above except make the binary variable a factor "DOMESTIC" vs "FOREIGN" for 0 and 1 respectively. Use RStudio's `View` function to ensure this worked as desired.

```{r}
#TO-DO
B_dataframe = data.frame(B)
B_dataframe[,6] <- ifelse(B_dataframe[,6] == 0, "DOMESTIC", "FOREIGN")
View(B_dataframe)
```

* Print out a table of the binary variable. Then print out the proportions of "DOMESTIC" vs "FOREIGN".

```{r}
#TO-DO
table(B_dataframe$X6)
table(B_dataframe$X6) / 100
```

Print out a summary of the whole dataframe.

```{r}
#TO-DO
B_dataframe$X6 = factor(B_dataframe$X6, labels = c("DOMESTIC", "FOREIGN")) 
summary(B_dataframe)
```

* Let `n = 50`. Create a n x n matrix `R` of exactly 50% entries 0's, 25% 1's 25% 2's. These values should be in random locations.

```{r}
#TO-DO ##########################
R = matrix(sample(c(0,1,2), size=50 , replace=TRUE, p = c(0.5,0.25,0.25)), nrow = 50, ncol = 50)
View(R)
table(R)
```

* Randomly punch holes (i.e. `NA`) values in this matrix so that an each entry is missing with probability 30%.

```{r}
#TO-DO ##########################
R[sample(1:length(R), length(R)*0.3)] <- NA
table(R)
R

```

* Sort the rows in matrix `R` by the largest row sum to lowest. Be careful about the NA's!

```{r}
#TO-DO
sorted_rowSum <- R[order(rowSums(R[,], na.rm = TRUE), decreasing=TRUE),]
#sanity check
#rowSums(sorted_rowSum, na.rm = TRUE)
sorted_rowSum
```

* We will now learn the `apply` function. This is a handy function that saves writing for loops which should be eschewed in R. Use the apply function to compute a vector whose entries are the standard deviation of each row. Use the apply function to compute a vector whose entries are the standard deviation of each column. Be careful about the NA's! This should be one line.

```{r}
#TO-DO
apply(R,1,sd, na.rm=TRUE)
apply(R,2,sd, na.rm=TRUE)
```

* Use the `apply` function to compute a vector whose entries are the count of entries that are 1 or 2 in each column. This should be one line.

```{r}
#TO-DO
apply(R != 0 ,2,sum, na.rm=TRUE)
```

* Use the `split` function to create a list whose keys are the column number and values are the vector of the columns. Look at the last example in the documentation `?split`.

```{r}
#TO-DO
split(R, col(R))
```

* In one statement, use the `lapply` function to create a list whose keys are the column number and values are themselves a list with keys: "min" whose value is the minimum of the column, "max" whose value is the maximum of the column, "pct_missing" is the proportion of missingness in the column and "first_NA" whose value is the row number of the first time the NA appears.

```{r}
#TO-DO
lapply(split(R,col(R)), function(x) list(min =min(x,na.rm=TRUE), max =max(x,na.rm=TRUE), pct_missing = (sum(is.na(x))/length(x)), first_NA = min(which(is.na(x)))))

```

* Set a seed and then create a vector `v` consisting of a sample of 1,000 iid normal realizations with mean -10 and variance 100.

```{r}
#TO-DO
set.seed(2021)
v <- rnorm(n = 1000, mean = -10, sd = sqrt(100))
v
```

* Repeat this exercise by resetting the seed to ensure you obtain the same results.

```{r}
#TO-DO
set.seed(2021)
x <- rnorm(n = 1000, mean = -10, sd = sqrt(100))
x
```

* Find the average of `v` and the standard error of `v`.

```{r}
#TO-DO
mean(v)
sd(v)
```

* Find the 5%ile of `v` and use the `qnorm` function to compute what it theoretically should be. Is the estimate about what is expected by theory?
  
```{r}
#TO-DO
quantile(v, probs = 0.05)
qnorm( p = 0.05, mean = -10, sd = sqrt(100))
#Yes it is expected
```

* What is the percentile of `v` that corresponds to the value 0? What should it be theoretically? Is the estimate about what is expected by theory?

```{r}
#TO-DO
inverse_quantile_object = ecdf(v)
inverse_quantile_object(0)

#The theoretical value of 0 should be 0.84134475. The empirical value is close to the theoretical value.
```